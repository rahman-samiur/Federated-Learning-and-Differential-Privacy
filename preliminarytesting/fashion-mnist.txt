import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import numpy as np

class SimpleCNN(nn.Module):
    """
    A simple CNN model as specified in the paper 
    for Fashion-MNIST.
    """
    def __init__(self):
        super(SimpleCNN, self).__init__()
        self.conv1 = nn.Conv2d(1, 32, kernel_size=5)
        self.pool = nn.MaxPool2d(2, 2)
        self.conv2 = nn.Conv2d(32, 64, kernel_size=5)
        self.fc1 = nn.Linear(64 * 4 * 4, 512) # 4x4 comes from 28x28 -> 24x24 -> 12x12 -> 8x8 -> 4x4
        self.fc2 = nn.Linear(512, 10)

    def forward(self, x):
        x = self.pool(F.relu(self.conv1(x)))
        x = self.pool(F.relu(self.conv2(x)))
        x = x.view(-1, 64 * 4 * 4)
        x = F.relu(self.fc1(x))
        x = self.fc2(x)
        return x

def get_dataloaders(num_clients=20, iid=True, batch_size=64, non_iid_alpha=0.5):
    """
    Loads Fashion-MNIST  and distributes it to clients.
    Supports IID  and Non-IID (Dirichlet).
    """
    transform = transforms.Compose([
        transforms.ToTensor(),
        transforms.Normalize((0.5,), (0.5,))
    ])
    
    # Load training data
    train_dataset = datasets.FashionMNIST(
        root='./data', train=True, download=True, transform=transform
    )
    
    # Load test data
    test_loader = DataLoader(
        datasets.FashionMNIST(root='./data', train=False, transform=transform),
        batch_size=1024, shuffle=False
    )

    client_dataloaders = []
    
    if iid:
        # IID: Shuffle and split data equally 
        num_samples_per_client = len(train_dataset) // num_clients
        indices = list(range(len(train_dataset)))
        np.random.shuffle(indices)
        
        for i in range(num_clients):
            client_indices = indices[i * num_samples_per_client : (i + 1) * num_samples_per_client]
            client_subset = Subset(train_dataset, client_indices)
            loader = DataLoader(client_subset, batch_size=batch_size, shuffle=True)
            client_dataloaders.append(loader)
            
    else:
        # Non-IID: Sampled from Dirichlet distribution 
        num_classes = 10
        labels = np.array(train_dataset.targets)
        
        # Generate Dirichlet distribution for label distribution per client
        client_shares = np.random.dirichlet(
            [non_iid_alpha] * num_classes, num_clients
        )
        
        # (Detailed Dirichlet logic would go here, partitioning indices based on labels)
        # For simplicity, this is a complex implementation step.
        # A common approach is to sort by label and assign skewed partitions.
        # Let's use a simplified label-skew approach for now:
        print("Warning: Using simplified non-IID. For paper, implement Dirichlet.")
        
        # Simple 2-class non-IID for demonstration
        # A real implementation would use the Dirichlet distribution
        indices_by_class = [np.where(labels == i)[0] for i in range(num_classes)]
        indices_per_client = [[] for _ in range(num_clients)]
        
        # Each client gets data from 2 classes
        for i in range(num_clients):
            class_a = i % num_classes
            class_b = (i + 1) % num_classes
            
            indices_a = np.random.choice(indices_by_class[class_a], 1500, replace=True)
            indices_b = np.random.choice(indices_by_class[class_b], 1500, replace=True)
            
            client_indices = np.concatenate([indices_a, indices_b])
            np.random.shuffle(client_indices)
            
            client_subset = Subset(train_dataset, client_indices)
            loader = DataLoader(client_subset, batch_size=batch_size, shuffle=True)
            client_dataloaders.append(loader)

    return client_dataloaders, test_loader

# Example usage:
# iid_loaders, test_loader = get_dataloaders(num_clients=20, iid=True, batch_size=64)
# non_iid_loaders, _ = get_dataloaders(num_clients=20, iid=False, batch_size=64)